"""
Script de verificaci√≥n post-instalaci√≥n
Ejecutar desde Jupyter despu√©s de aplicar los cambios

Uso:
    exec(open('/home/jovyan/dev/sipi-etl/verify_install.py').read())
"""

import asyncio
import sys
from pathlib import Path

print("=" * 80)
print("SIPI-ETL: Verificaci√≥n de Instalaci√≥n")
print("=" * 80)
print()

# ============================================================================
# 1. Verificar estructura del proyecto
# ============================================================================
print("1Ô∏è‚É£  Verificando estructura del proyecto...")
print("-" * 80)

project_root = Path.cwd()
if (project_root / 'notebooks').exists():
    project_root = project_root.parent

required_paths = [
    'src',
    'src/modules',
    'src/modules/portals',
    'src/modules/portals/idealista',
    'src/core',
]

all_exist = True
for path in required_paths:
    full_path = project_root / path
    exists = full_path.exists()
    status = "‚úì" if exists else "‚úó"
    print(f"  {status} {path}")
    if not exists:
        all_exist = False

if not all_exist:
    print("\n‚ùå ERROR: Faltan directorios del proyecto")
    print(f"   Verificar que est√°s en el directorio correcto: {project_root}")
    sys.exit(1)

print(f"\n‚úì Estructura del proyecto correcta en: {project_root}")
print()

# Agregar al path si no est√°
if str(project_root) not in sys.path:
    sys.path.insert(0, str(project_root))

# ============================================================================
# 2. Verificar registry de scrapers
# ============================================================================
print("2Ô∏è‚É£  Verificando registry de scrapers...")
print("-" * 80)

try:
    from src.modules.portals.factory import _SCRAPER_REGISTRY, get_available_portals
    from src.core.etl_event_system import PortalType
    
    portals = get_available_portals()
    portal_names = [p.value for p in portals]
    
    print(f"  Scrapers registrados: {portal_names}")
    
    if PortalType.IDEALISTA in _SCRAPER_REGISTRY:
        print("  ‚úì Scraper Idealista encontrado")
    else:
        print("  ‚úó Scraper Idealista NO registrado")
        print("\n‚ùå ERROR: Registry vac√≠o o scraper no registrado")
        print("   Soluci√≥n: Verificar que __init__.py importa el scraper")
        sys.exit(1)
    
    print("\n‚úì Registry configurado correctamente")
    print()
    
except ImportError as e:
    print(f"  ‚úó Error importando m√≥dulos: {e}")
    print("\n‚ùå ERROR: No se pueden importar los m√≥dulos del proyecto")
    print("   Soluci√≥n: Verificar la estructura del proyecto y los imports")
    sys.exit(1)

# ============================================================================
# 3. Verificar conexi√≥n PostgreSQL
# ============================================================================
print("3Ô∏è‚É£  Verificando conexi√≥n PostgreSQL...")
print("-" * 80)

async def test_postgres():
    try:
        from src.modules.portals.base_loader import PostgresConnectionPool
        import os
        
        # Mostrar configuraci√≥n
        host = os.getenv('POSTGRES_HOST', 'postgis')
        port = os.getenv('POSTGRES_PORT', '5432')
        user = os.getenv('POSTGRES_USER', 'user')
        db = os.getenv('POSTGRES_DB', 'spatialdb')
        
        print(f"  Configuraci√≥n:")
        print(f"    Host: {host}")
        print(f"    Puerto: {port}")
        print(f"    Usuario: {user}")
        print(f"    Base de datos: {db}")
        print()
        
        # Intentar conexi√≥n
        print("  Intentando conectar...")
        pool = await PostgresConnectionPool.get_pool()
        
        async with pool.acquire() as conn:
            version = await conn.fetchval('SELECT version()')
            pg_version = version.split(',')[0]
            print(f"  ‚úì Conectado a: {pg_version}")
            
            # Verificar esquema portals
            schema_exists = await conn.fetchval(
                "SELECT EXISTS(SELECT 1 FROM information_schema.schemata WHERE schema_name = 'portals')"
            )
            
            if schema_exists:
                print("  ‚úì Esquema 'portals' existe")
                
                # Verificar tablas principales
                tables_to_check = ['inmuebles_raw', 'detecciones', 'cambios', 'duplicates']
                
                for table_name in tables_to_check:
                    table_exists = await conn.fetchval(
                        "SELECT EXISTS(SELECT 1 FROM information_schema.tables "
                        "WHERE table_schema = 'portals' AND table_name = $1)", table_name
                    )
                    
                    if table_exists:
                        count = await conn.fetchval(f"SELECT COUNT(*) FROM portals.{table_name}")
                        print(f"  ‚úì Tabla 'portals.{table_name}' existe ({count} registros)")
                    else:
                        print(f"  ‚ö† Tabla 'portals.{table_name}' no existe")
                        print(f"    Ejecuta: init_db_real.py")
            else:
                print("  ‚ö† Esquema 'portals' no existe")
                print("    (Ejecuta init_db_real.py para crear el esquema)")
        
        await PostgresConnectionPool.close_pool()
        print("\n‚úì PostgreSQL funcionando correctamente")
        return True
        
    except Exception as e:
        print(f"\n‚ùå ERROR conectando a PostgreSQL: {e}")
        print("\nPosibles causas:")
        print("  1. El contenedor 'postgis' no est√° corriendo")
        print("  2. Las credenciales son incorrectas")
        print("  3. El host deber√≠a ser 'postgis' (no 'localhost')")
        print("\nVerificar con: docker ps | grep postgis")
        return False

postgres_ok = asyncio.run(test_postgres())
print()

if not postgres_ok:
    sys.exit(1)

# ============================================================================
# 4. Verificar Redis (opcional)
# ============================================================================
print("4Ô∏è‚É£  Verificando conexi√≥n Redis...")
print("-" * 80)

async def test_redis():
    try:
        from src.modules.portals.redis_cache import RedisCache
        import os
        
        # Mostrar configuraci√≥n
        host = os.getenv('REDIS_HOST', 'redis')
        port = os.getenv('REDIS_PORT', '6379')
        
        print(f"  Configuraci√≥n:")
        print(f"    Host: {host}")
        print(f"    Puerto: {port}")
        print()
        
        # Intentar conexi√≥n
        print("  Intentando conectar...")
        cache = RedisCache()
        await cache.connect()
        
        # Test b√°sico
        test_key = 'test_verify_install'
        is_dup_1 = await cache.check_duplicate('test', test_key, ttl_hours=1)
        is_dup_2 = await cache.check_duplicate('test', test_key, ttl_hours=1)
        
        await cache.close()
        
        if not is_dup_1 and is_dup_2:
            print("  ‚úì Redis funcionando correctamente")
            print("  ‚úì Deduplicaci√≥n funcional")
            print("\n‚úì Redis disponible")
            return True
        else:
            print("  ‚ö† Redis conecta pero la deduplicaci√≥n no funciona como esperado")
            return False
        
    except Exception as e:
        print(f"  ‚ö† Redis no disponible: {e}")
        print("  (Opcional - el sistema puede funcionar sin Redis)")
        print("  La deduplicaci√≥n estar√° deshabilitada")
        return False

redis_ok = asyncio.run(test_redis())
print()

# ============================================================================
# 5. Test de scraper
# ============================================================================
print("5Ô∏è‚É£  Verificando scraper de Idealista...")
print("-" * 80)

try:
    from src.modules.portals.factory import create_scraper
    from src.core.etl_event_system import PortalType
    
    print("  Creando instancia del scraper...")
    scraper = create_scraper(PortalType.IDEALISTA)
    
    print(f"  ‚úì Scraper creado: {scraper.__class__.__name__}")
    print(f"  ‚úì Portal: {scraper.portal_type.value}")
    print(f"  ‚úì Base URL: {scraper.base_url}")
    
    # Test de m√©todo get_search_url
    test_url = scraper.get_search_url(provincia='sevilla', pagina=1)
    print(f"  ‚úì URL de prueba generada: {test_url}")
    
    print("\n‚úì Scraper funcionando correctamente")
    
except Exception as e:
    print(f"\n‚ùå ERROR creando scraper: {e}")
    sys.exit(1)

print()

# ============================================================================
# Resumen final
# ============================================================================
print("=" * 80)
print("üìä RESUMEN DE VERIFICACI√ìN")
print("=" * 80)
print()
print("‚úì Estructura del proyecto")
print("‚úì Registry de scrapers")
print("‚úì Conexi√≥n PostgreSQL" if postgres_ok else "‚úó Conexi√≥n PostgreSQL")
print("‚úì Conexi√≥n Redis" if redis_ok else "‚ö† Redis no disponible (opcional)")
print("‚úì Scraper Idealista")
print()

if postgres_ok:
    print("üéâ ¬°Todo listo! Puedes usar el notebook test_pipeline_fixed.ipynb")
    print()
    print("Pr√≥ximos pasos:")
    print("  1. Abrir test_pipeline_fixed.ipynb")
    print("  2. Ejecutar las celdas en orden")
    print("  3. Verificar que no hay errores")
    print()
else:
    print("‚ö† Hay problemas que resolver antes de continuar")
    print("   Revisa los errores arriba y aplica las soluciones sugeridas")
    print()

print("=" * 80)